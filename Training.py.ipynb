{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LittleVGG for DeepCam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Emotion Detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "num_classes = 7\n",
    "img_rows, img_cols = 48, 48\n",
    "batch_size = 16\n",
    "\n",
    "# using fer2013 dataset with faces labelled with emotions\n",
    "train_data_dir = './fer2013/train'\n",
    "validation_data_dir = './fer2013/validation'\n",
    "\n",
    "# augmenting data as dataset is not so large\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=30,\n",
    "      shear_range=0.3,\n",
    "      zoom_range=0.3,\n",
    "      width_shift_range=0.4,\n",
    "      height_shift_range=0.4,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Keras Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras LittleVGG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 455       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 1,328,167\n",
      "Trainable params: 1,325,991\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same', kernel_initializer=\"he_normal\",\n",
    "                 input_shape = (img_rows, img_cols, 1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), padding = \"same\", kernel_initializer=\"he_normal\", \n",
    "                 input_shape = (img_rows, img_cols, 1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block #2: second CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block #3: third CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block #4: third CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block #5: first set of FC => RELU layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block #6: second set of FC => RELU layers\n",
    "model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block #7: softmax classifier\n",
    "model.add(Dense(num_classes, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1794/1794 [==============================] - 894s 498ms/step - loss: 2.0482 - acc: 0.2059 - val_loss: 1.7890 - val_acc: 0.2508\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.78897, saving model to ./Trained Models/emotion_little_vgg_3.h5\n",
      "Epoch 2/10\n",
      "1794/1794 [==============================] - 991s 553ms/step - loss: 1.8039 - acc: 0.2473 - val_loss: 1.7812 - val_acc: 0.2648\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.78897 to 1.78115, saving model to ./Trained Models/emotion_little_vgg_3.h5\n",
      "Epoch 3/10\n",
      "1794/1794 [==============================] - 940s 524ms/step - loss: 1.7871 - acc: 0.2552 - val_loss: 1.7638 - val_acc: 0.2816\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.78115 to 1.76381, saving model to ./Trained Models/emotion_little_vgg_3.h5\n",
      "Epoch 4/10\n",
      "1794/1794 [==============================] - 1031s 575ms/step - loss: 1.7571 - acc: 0.2729 - val_loss: 1.7166 - val_acc: 0.3135\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.76381 to 1.71661, saving model to ./Trained Models/emotion_little_vgg_3.h5\n",
      "Epoch 5/10\n",
      "1794/1794 [==============================] - 868s 484ms/step - loss: 1.7181 - acc: 0.2963 - val_loss: 1.6794 - val_acc: 0.3546\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.71661 to 1.67942, saving model to ./Trained Models/emotion_little_vgg_3.h5\n",
      "Epoch 6/10\n",
      "1794/1794 [==============================] - 869s 484ms/step - loss: 1.6393 - acc: 0.3456 - val_loss: 1.5434 - val_acc: 0.4086\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.67942 to 1.54344, saving model to ./Trained Models/emotion_little_vgg_3.h5\n",
      "Epoch 7/10\n",
      "1794/1794 [==============================] - 871s 485ms/step - loss: 1.5629 - acc: 0.3894 - val_loss: 1.5187 - val_acc: 0.4100\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.54344 to 1.51868, saving model to ./Trained Models/emotion_little_vgg_3.h5\n",
      "Epoch 8/10\n",
      "1794/1794 [==============================] - 888s 495ms/step - loss: 1.5146 - acc: 0.4154 - val_loss: 1.5393 - val_acc: 0.4489\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.51868\n",
      "Epoch 9/10\n",
      "1794/1794 [==============================] - 873s 487ms/step - loss: 1.4794 - acc: 0.4303 - val_loss: 1.4941 - val_acc: 0.4377\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.51868 to 1.49406, saving model to ./Trained Models/emotion_little_vgg_3.h5\n",
      "Epoch 10/10\n",
      "1794/1794 [==============================] - 846s 472ms/step - loss: 1.4514 - acc: 0.4426 - val_loss: 1.4862 - val_acc: 0.4610\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.49406 to 1.48616, saving model to ./Trained Models/emotion_little_vgg_3.h5\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Early Stopping Setup\n",
    "checkpoint = ModelCheckpoint(\"./Trained Models/emotion_little_vgg_3.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 3, verbose = 1, min_delta = 0.0001)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint, reduce_lr]\n",
    "\n",
    "# We use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adam(lr=0.001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "nb_validation_samples = 3589\n",
    "epochs = 10\n",
    "nb_train_samples=28709\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3589 images belonging to 7 classes.\n",
      "Confusion Matrix\n",
      "[[156   0  20  36 106 129  44]\n",
      " [ 29   0   0   4   0  18   4]\n",
      " [ 92   0  30  33 138 102 133]\n",
      " [ 24   0   2 728  69  23  33]\n",
      " [ 75   0  17 151 189  94 100]\n",
      " [ 43   0  18  50 249 217  17]\n",
      " [ 11   0  12  26  28   9 330]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.36      0.32      0.34       491\n",
      "     Disgust       0.00      0.00      0.00        55\n",
      "        Fear       0.30      0.06      0.10       528\n",
      "       Happy       0.71      0.83      0.76       879\n",
      "     Neutral       0.24      0.30      0.27       626\n",
      "         Sad       0.37      0.37      0.37       594\n",
      "    Surprise       0.50      0.79      0.61       416\n",
      "\n",
      "   micro avg       0.46      0.46      0.46      3589\n",
      "   macro avg       0.35      0.38      0.35      3589\n",
      "weighted avg       0.43      0.46      0.43      3589\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "nb_train_samples = 28709\n",
    "nb_validation_samples = 3589\n",
    "\n",
    "# recreate our validation generator with shuffle = false\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = list(class_labels.values())\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "cnf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n",
    "\n",
    "plt.imshow(cnf_matrix, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "_ = plt.xticks(tick_marks, classes, rotation=90)\n",
    "_ = plt.yticks(tick_marks, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows the uncertainity of the dataset and needs more data to train the model for better recognition. Though we acquired an accuracy of 46% with data augmentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "classifier = load_model('./Trained Models/emotion_little_vgg_3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get our class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3589 images belonging to 7 classes.\n",
      "{0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Neutral', 5: 'Sad', 6: 'Surprise'}\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webcam test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('./Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return (0,0,0,0), np.zeros((48,48), np.uint8), img\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "\n",
    "    try:\n",
    "        roi_gray = cv2.resize(roi_gray, (48, 48), interpolation = cv2.INTER_AREA)\n",
    "    except:\n",
    "        return (x,w,y,h), np.zeros((48,48), np.uint8), img\n",
    "    return (x,w,y,h), roi_gray, img\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    rect, face, image = face_detector(frame)\n",
    "    if np.sum([face]) != 0.0:\n",
    "        roi = face.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi, axis=0)\n",
    "\n",
    "        # make a prediction on the ROI, then lookup the class\n",
    "        preds = classifier.predict(roi)[0]\n",
    "        label = class_labels[preds.argmax()]  \n",
    "        label_position = (rect[0] + int((rect[1]/2)), rect[2] + 25)\n",
    "        cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,2, (0,255,0), 3)\n",
    "    else:\n",
    "        cv2.putText(image, \"No Face Found\", (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,2, (0,255,0), 3)\n",
    "        \n",
    "    cv2.imshow('All', image)\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
